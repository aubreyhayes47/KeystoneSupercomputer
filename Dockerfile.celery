# Celery Worker Dockerfile for Keystone Supercomputer
# Handles background job processing for simulation orchestration
# Optimized with multi-stage build and minimal packages

# Build stage: Install dependencies
FROM python:3.11-slim AS builder

WORKDIR /build

# Copy requirements and install to a specific location
COPY requirements.txt .
RUN pip install --no-cache-dir --user --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt

# Runtime stage: Minimal image with only necessary components
FROM python:3.11-slim

# Install only runtime dependencies (Docker CLI and Docker Compose)
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        docker.io \
        docker-compose \
        ca-certificates && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

# Copy Python packages from builder
COPY --from=builder /root/.local /root/.local

# Set working directory
WORKDIR /app

# Copy only the Celery application (minimal context)
COPY src/celery_app.py .

# Create directory for task artifacts
RUN mkdir -p /data

# Set environment variables for performance and reliability
ENV PYTHONUNBUFFERED=1 \
    CELERY_BROKER_URL=redis://redis:6379/0 \
    CELERY_RESULT_BACKEND=redis://redis:6379/0 \
    PATH=/root/.local/bin:$PATH \
    PYTHONDONTWRITEBYTECODE=1

# Run Celery worker with optimized settings
CMD ["celery", "-A", "celery_app", "worker", "--loglevel=info", "--concurrency=2", "--max-tasks-per-child=1000"]
