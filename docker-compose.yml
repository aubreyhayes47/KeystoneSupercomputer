services:
  # Redis - Message broker and cache for background job queue
  redis:
    image: redis:7-alpine
    container_name: keystone-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - keystone-network
    restart: unless-stopped

  # FEniCSx Simulation Service
  # Supports MPI for parallel execution
  # Usage: docker compose run --rm fenicsx mpirun -np 4 python3 script.py
  # For GPU acceleration, see docker-compose.gpu.yml and GPU_ACCELERATION.md
  fenicsx:
    build:
      context: ./src/sim-toolbox/fenicsx
      dockerfile: Dockerfile
    image: fenicsx-toolbox:latest
    container_name: keystone-fenicsx
    volumes:
      - ./data/fenicsx:/data
      - ./src/sim-toolbox/fenicsx:/app
    environment:
      - PYTHONUNBUFFERED=1
      - SIMULATION_TYPE=fenicsx
    networks:
      - keystone-network
    # Service runs on-demand, not continuously
    profiles:
      - simulation

  # LAMMPS Simulation Service
  # Supports both OpenMP and MPI for parallel execution
  # Usage: docker compose run --rm lammps mpirun -np 4 --allow-run-as-root lmp -in input.lammps
  #    or: docker compose run --rm -e OMP_NUM_THREADS=4 lammps lmp -in input.lammps
  # For GPU acceleration, see docker-compose.gpu.yml and GPU_ACCELERATION.md
  lammps:
    build:
      context: ./src/sim-toolbox/lammps
      dockerfile: Dockerfile
    image: keystone/lammps:latest
    container_name: keystone-lammps
    volumes:
      - ./data/lammps:/data
    environment:
      - SIMULATION_TYPE=lammps
    networks:
      - keystone-network
    # Service runs on-demand, not continuously
    profiles:
      - simulation

  # OpenFOAM Simulation Service
  # Supports MPI for parallel execution
  # Usage: docker compose run --rm openfoam decomposePar && \
  #        docker compose run --rm openfoam mpirun -np 4 --allow-run-as-root simpleFoam -parallel
  # For GPU acceleration, see docker-compose.gpu.yml and GPU_ACCELERATION.md
  openfoam:
    build:
      context: ./src/sim-toolbox/openfoam
      dockerfile: Dockerfile
    image: openfoam-toolbox:latest
    container_name: keystone-openfoam
    volumes:
      - ./data/openfoam:/data
      - ./src/sim-toolbox/openfoam:/workspace
    environment:
      - PYTHONUNBUFFERED=1
      - SIMULATION_TYPE=openfoam
      - FOAM_RUN=/workspace/foam-run
    networks:
      - keystone-network
    # Service runs on-demand, not continuously
    profiles:
      - simulation

  # Celery Worker - Background job processing
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile.celery
    image: keystone-celery-worker:latest
    container_name: keystone-celery-worker
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./src/celery_app.py:/app/celery_app.py
      - ./data:/data
      - /var/run/docker.sock:/var/run/docker.sock  # Allow worker to execute docker commands
      - ./docker-compose.yml:/app/docker-compose.yml:ro
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - PYTHONUNBUFFERED=1
    networks:
      - keystone-network
    restart: unless-stopped

  # Agent Service - CLI and orchestration (future enhancement)
  # Uncomment when ready to integrate with the agentic core
  # agent:
  #   build:
  #     context: ./src/agent
  #     dockerfile: Dockerfile
  #   image: keystone-agent:latest
  #   container_name: keystone-agent
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #   volumes:
  #     - ./src/agent:/app
  #     - ./data:/data
  #   environment:
  #     - REDIS_URL=redis://redis:6379
  #     - OLLAMA_BASE_URL=http://host.docker.internal:11434
  #   networks:
  #     - keystone-network
  #   stdin_open: true
  #   tty: true

networks:
  keystone-network:
    driver: bridge
    name: keystone-network

volumes:
  redis-data:
    name: keystone-redis-data
