# GPU-Enabled Configuration for Keystone Simulation
# Optimized for GPU-accelerated simulations with NVIDIA, Intel, or AMD GPUs
#
# Usage:
#   helm install keystone-sim k8s/helm/keystone-simulation \
#     -n keystone --create-namespace -f k8s/helm/values-gpu.yaml

# Global settings
global:
  namespace: keystone
  imagePullPolicy: Never  # Use local images for development

# Redis configuration (no GPU needed)
redis:
  enabled: true
  image:
    repository: redis
    tag: "7-alpine"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 6379
  persistence:
    enabled: true
    storageClass: ""
    size: 5Gi
    accessMode: ReadWriteOnce
  resources:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "1000m"

# ==============================================================================
# Celery Worker GPU Configurations
# ==============================================================================

celeryWorker:
  enabled: true
  replicaCount: 2
  image:
    repository: keystone-celery-worker
    tag: latest
    pullPolicy: Never
  config:
    brokerUrl: "redis://redis:6379/0"
    resultBackend: "redis://redis:6379/0"
  volumes:
    dataPath: /data
    celeryAppPath: /home/runner/work/KeystoneSupercomputer/KeystoneSupercomputer/src/celery_app.py
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "2000m"

# ==============================================================================
# NVIDIA GPU Simulation Configurations
# ==============================================================================

# FEniCSx with NVIDIA GPU
fenicsx:
  enabled: true
  image:
    repository: fenicsx-toolbox
    tag: latest
    pullPolicy: Never
  jobTemplate:
    suspend: true
  config:
    simulationType: "fenicsx"
  volumes:
    dataPath: /data/fenicsx
    scriptsPath: /home/runner/work/KeystoneSupercomputer/KeystoneSupercomputer/src/sim-toolbox/fenicsx
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "16Gi"
      cpu: "8000m"
      nvidia.com/gpu: 1  # Request 1 NVIDIA GPU
  # Target nodes with NVIDIA GPUs
  nodeSelector:
    accelerator: nvidia-gpu
  # Allow scheduling on GPU-tainted nodes
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

# LAMMPS with NVIDIA GPU
lammps:
  enabled: true
  image:
    repository: keystone/lammps
    tag: latest
    pullPolicy: Never
  jobTemplate:
    suspend: true
  config:
    simulationType: "lammps"
  volumes:
    dataPath: /data/lammps
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "16Gi"
      cpu: "8000m"
      nvidia.com/gpu: 1  # Request 1 NVIDIA GPU
  nodeSelector:
    accelerator: nvidia-gpu
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

# OpenFOAM with NVIDIA GPU
openfoam:
  enabled: true
  image:
    repository: openfoam-toolbox
    tag: latest
    pullPolicy: Never
  jobTemplate:
    suspend: true
  config:
    simulationType: "openfoam"
    foamRun: "/workspace/foam-run"
  volumes:
    dataPath: /data/openfoam
    workspacePath: /home/runner/work/KeystoneSupercomputer/KeystoneSupercomputer/src/sim-toolbox/openfoam
  resources:
    requests:
      memory: "4Gi"
      cpu: "2000m"
    limits:
      memory: "16Gi"
      cpu: "8000m"
      nvidia.com/gpu: 1  # Request 1 NVIDIA GPU
  nodeSelector:
    accelerator: nvidia-gpu
  tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

# ==============================================================================
# Intel GPU Alternative Configurations
# ==============================================================================
# To use Intel GPU instead of NVIDIA, uncomment and modify the sections above:
#
# fenicsx:
#   resources:
#     limits:
#       gpu.intel.com/i915: 1  # Request 1 Intel GPU
#   nodeSelector:
#     accelerator: intel-gpu
#   tolerations:
#   - key: gpu.intel.com/i915
#     operator: Exists
#     effect: NoSchedule
#
# Similar configuration for lammps and openfoam

# ==============================================================================
# AMD GPU Alternative Configurations  
# ==============================================================================
# To use AMD GPU instead of NVIDIA, uncomment and modify the sections above:
#
# fenicsx:
#   resources:
#     limits:
#       amd.com/gpu: 1  # Request 1 AMD GPU
#   nodeSelector:
#     accelerator: amd-gpu
#   tolerations:
#   - key: amd.com/gpu
#     operator: Exists
#     effect: NoSchedule
#
# Similar configuration for lammps and openfoam

# ==============================================================================
# Multi-GPU Configuration Example
# ==============================================================================
# To request multiple GPUs for a single simulation:
#
# fenicsx:
#   resources:
#     limits:
#       nvidia.com/gpu: 2  # Request 2 GPUs
#       # or
#       gpu.intel.com/i915: 2
#       # or
#       amd.com/gpu: 2
#
#   # Optional: Set GPU affinity via environment variables
#   env:
#   - name: CUDA_VISIBLE_DEVICES
#     value: "0,1"  # For NVIDIA
#   # or
#   - name: ZE_AFFINITY_MASK
#     value: "0,1"  # For Intel
#   # or
#   - name: HIP_VISIBLE_DEVICES
#     value: "0,1"  # For AMD

# ==============================================================================
# GPU Node Affinity Configuration
# ==============================================================================
# For more sophisticated node selection based on GPU type and count:
#
# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#       - matchExpressions:
#         - key: accelerator
#           operator: In
#           values:
#           - nvidia-gpu
#           - nvidia-a100
#           - nvidia-v100
#     preferredDuringSchedulingIgnoredDuringExecution:
#     - weight: 100
#       preference:
#         matchExpressions:
#         - key: gpu-count
#           operator: Gt
#           values:
#           - "1"

# ==============================================================================
# Additional Environment Variables
# ==============================================================================
# Common GPU-related environment variables that can be added to any service:
#
# NVIDIA GPU:
#   - CUDA_VISIBLE_DEVICES: "0,1"  # Select specific GPUs
#   - NVIDIA_VISIBLE_DEVICES: "all"  # Make all GPUs visible
#   - NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
#
# Intel GPU:
#   - ZE_AFFINITY_MASK: "0"  # Target specific GPU
#   - ONEAPI_DEVICE_SELECTOR: "level_zero:gpu"
#
# AMD GPU:
#   - HIP_VISIBLE_DEVICES: "0,1"  # Select specific GPUs
#   - HSA_OVERRIDE_GFX_VERSION: "10.3.0"  # Override GPU architecture
#   - ROCR_VISIBLE_DEVICES: "0"  # ROCr device selection

# ==============================================================================
# Installation Commands
# ==============================================================================
#
# Install with NVIDIA GPU support:
#   helm install keystone-sim k8s/helm/keystone-simulation \
#     -n keystone --create-namespace \
#     -f k8s/helm/values-gpu.yaml
#
# Install with custom GPU count:
#   helm install keystone-sim k8s/helm/keystone-simulation \
#     -n keystone --create-namespace \
#     -f k8s/helm/values-gpu.yaml \
#     --set fenicsx.resources.limits.nvidia\.com/gpu=2
#
# Upgrade to change GPU configuration:
#   helm upgrade keystone-sim k8s/helm/keystone-simulation \
#     -n keystone \
#     -f k8s/helm/values-gpu.yaml \
#     --set fenicsx.resources.limits.nvidia\.com/gpu=4
#
# ==============================================================================
# Prerequisites
# ==============================================================================
#
# Before deploying, ensure:
#
# 1. NVIDIA GPU Operator is installed (for NVIDIA):
#    kubectl apply -f https://raw.githubusercontent.com/NVIDIA/gpu-operator/v23.9.0/deployments/gpu-operator/nvidia-gpu-operator.yaml
#
# 2. Intel Device Plugin is installed (for Intel):
#    kubectl apply -k 'https://github.com/intel/intel-device-plugins-for-kubernetes/deployments/gpu_plugin?ref=v0.29.0'
#
# 3. AMD Device Plugin is installed (for AMD):
#    kubectl create -f https://raw.githubusercontent.com/RadeonOpenCompute/k8s-device-plugin/master/k8s-ds-amdgpu-dp.yaml
#
# 4. GPU nodes are properly labeled:
#    kubectl label nodes <node-name> accelerator=nvidia-gpu
#    # or
#    kubectl label nodes <node-name> accelerator=intel-gpu
#    # or
#    kubectl label nodes <node-name> accelerator=amd-gpu
#
# ==============================================================================
